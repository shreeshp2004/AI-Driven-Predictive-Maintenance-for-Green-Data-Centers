# ğŸŒ± AI-Driven Predictive Maintenance for Green Data Centers

A machine learning framework for **energy consumption forecasting and carbon footprint analysis** using time-series feature engineering and Random Forest optimization.

---

## ğŸš€ Overview

This project builds an intelligent energy analytics pipeline that:

* Predicts data center power consumption
* Estimates carbon emissions
* Detects high vs low energy usage patterns
* Optimizes model performance using GridSearchCV

The system is designed to support **green data center initiatives** by enabling data-driven energy optimization and sustainability monitoring.

---

## ğŸ¯ Key Features

âœ… Time-series feature engineering from datetime
âœ… Random Forest regression with hyperparameter tuning
âœ… Energy â†’ Carbon emission estimation
âœ… Binary energy classification (High vs Low usage)
âœ… Confusion matrix visualization
âœ… Model persistence using Joblib
âœ… Multiple performance metrics

---

## ğŸ§  Methodology

### 1ï¸âƒ£ Data Preprocessing

* Convert `Datetime` to pandas datetime
* Extract temporal features:

  * Year
  * Month
  * Day
  * Hour
  * DayOfWeek
* Handle missing values
* Train-test split (80/20)

---

### 2ï¸âƒ£ Model Training

Model used:

```
RandomForestRegressor
```

Hyperparameter tuning via:

```
GridSearchCV
```

Parameters optimized:

* n_estimators
* max_depth
* min_samples_split
* min_samples_leaf

---

### 3ï¸âƒ£ Evaluation Metrics

#### ğŸ”¹ Regression Metrics

* MAE
* MSE
* RMSE
* RÂ² Score

#### ğŸ”¹ Classification Metrics

(derived using median threshold)

* Accuracy
* Precision
* Recall
* F1-Score
* Confusion Matrix

---

## ğŸ“Š Visualizations Generated

The pipeline automatically produces:

* ğŸ“ˆ Energy consumption trend
* ğŸŒ Carbon emission trend
* ğŸ”² Confusion matrix
* ğŸ“‰ Training vs validation curves

---

## ğŸ“ Dataset

Expected file:

```
AEP_hourly.csv
```

Required columns:

* Datetime
* AEP_MW

Place the dataset in the project root before running.

---

## âš™ï¸ Installation

```bash
git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git
cd YOUR_REPO
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

```bash
python your_script_name.py
```

After execution, the model will be saved as:

```
optimized_carbon_footprint_model.pkl
```

---

## ğŸ§ª Example Output

The script prints:

* Regression performance
* Classification performance
* Confusion matrix
* Graphical analysis

---

## ğŸ› ï¸ Tech Stack

* Python
* Pandas
* NumPy
* Scikit-learn
* Matplotlib
* Seaborn
* Joblib

---

## ğŸ“¦ Model File

Trained model:

```
optimized_carbon_footprint_model.pkl
```

> âš ï¸ Large model files are tracked using Git LFS (recommended).

---

## ğŸŒ Sustainability Impact

This work supports:

* Green data center optimization
* Carbon footprint awareness
* Energy-efficient infrastructure planning
* AI-driven sustainability analytics

---

## ğŸ‘¨â€ğŸ’» Author

**Shreesh Prateek Pathak**
B.Tech ECE (Biomedical Specialization)
VIT Vellore

---

## ğŸ“œ License

MIT License

---

## â­ Future Improvements

* Federated learning integration
* Real-time IoT data ingestion
* Deep learning models (LSTM/Transformer)
* Explainable AI (XAI)
* Deployment dashboard
